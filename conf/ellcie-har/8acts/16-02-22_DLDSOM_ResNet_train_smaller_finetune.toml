[bench]
name = "Ellcie-HAR_DLDSOM_ResNet_train"
seed = 5
first_run = 1
last_run = 15
plugins = ['qualia_plugin_som']

[learningframework]
kind = 'PyTorchDLSOM'

[deploy]
target = 'Linux'
converter.kind = 'QualiaCodeGen'
quantize = ['float32']
optimize = ['']

[dataset]
kind = "EllcieHAR"
params.variant = "UCA-EHAR"
params.path = "data/UCA-EHAR_16-02-22"

#[experimenttracking]
#kind = "Neptune"
#params.config = 'conf/neptune.toml'
#params.project_name = 'MicroAI-EllcieHAR'

[[preprocessing]]
kind = "RemoveActivity"
params.activities = [
	"STANDING",
	"STAND_TO_SIT",
	#"SITTING",
	"SIT_TO_STAND",
	#"WALKING",
	#"LYING",
	#"WALKING_DOWNSTAIRS",
	#"WALKING_UPSTAIRS",
	"DRIVING",
	##"NODDING",
	##"TRANSITION",
	#"RUNNING",
	#"DRINKING",
	"SIT_TO_LIE",
	"LIE_TO_SIT"
]

[[preprocessing]]
kind = "RemoveSensor"
params.sensorkinds = ["Barometer"]

#[[preprocessing]]
#kind = "BandPassFilter"
#params.f1 = 0.01
#params.f2 = 1.0
##params.f2 = 100.0
#params.sensorkind = "Barometer"
#params.dimension = "p"

[[preprocessing]]
kind = "DatasetSplitterBySubjects"
#['T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T10', 'T12', 'T13', 'T14', 'T16', 'T17', 'T18', 'T19', 'T20', 'T21']
#params.source_subjects = ['T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T10', 'T12', 'T13', 'T14', 'T16', 'T17', 'T18', 'T19', 'T20', 'T21']
#params.dest_subjects = []

# test subjects with drinking
#Result(combination=array(['T4', 'T5', 'T7', 'T19', 'T20'], dtype='<U3'), mean=24.50350249729214, std=1.4015159401704411, ratios=array([23.186762536873157, 26.93521146293022, 25.361542018749738,
#       23.375860439574474, 24.051639583278106, 23.106022896963662,
#       23.70202569105265, 26.308955348915138], dtype=object))
#params.source_subjects = ['T1', 'T2', 'T3', 'T6', 'T8', 'T9', 'T10', 'T12', 'T13', 'T14', 'T16', 'T17', 'T18', 'T21']
#params.dest_subjects = ['T4', 'T5', 'T7', 'T19', 'T20']

#params.source_subjects = ['T1', 'T4', 'T6', 'T8', 'T7', 'T9', 'T10', 'T12', 'T13', 'T14', 'T16', 'T17', 'T18', 'T19', 'T20', 'T21']
#params.dest_subjects = ['T2', 'T3', 'T5']
params.source_subjects = ['T1', 'T4', 'T6', 'T7', 'T8', 'T9', 'T10', 'T12', 'T13', 'T14', 'T15', 'T16', 'T17', 'T18', 'T19', 'T21']
params.dest_subjects = ['T2', 'T3', 'T5', 'T20']



#params.source_subjects = ['T1', 'T2', 'T5', 'T6', 'T7', 'T8', 'T9', 'T12', 'T13', 'T16', 'T17', 'T19', 'T20', 'T21'] # 'T15'
#params.dest_subjects = ['T3', 'T4', 'T10', 'T14', 'T18']

#params.source_subjects = ['T3', 'T4', 'T5', 'T6']
#params.dest_subjects = ['T1', 'T2']
#params.source_subjects = ['T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T12', 'T17', 'T18']
#params.dest_subjects = ['T19', 'T20', 'T21']

#params.source_subjects = ['T5', 'T6', 'T7', 'T8', 'T9', 'T10', 'T12', 'T13', 'T14', 'T16', 'T17', 'T18', 'T19', 'T20', 'T21']
#params.dest_subjects = ['T1', 'T2', 'T3', 'T4']
#params.source_subjects = ['T1', 'T2', 'T3', 'T4', 'T9', 'T10', 'T12', 'T13', 'T14', 'T16', 'T17', 'T18', 'T19', 'T20', 'T21']
#params.dest_subjects = ['T5', 'T6', 'T7', 'T8']
#params.source_subjects = ['T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T14', 'T16', 'T17', 'T18', 'T19', 'T20', 'T21']
#params.dest_subjects = ['T9', 'T10', 'T12', 'T13']
#params.source_subjects = ['T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T10', 'T12', 'T13', 'T19', 'T20', 'T21']
#params.dest_subjects = ['T14', 'T16', 'T17', 'T18']
#params.source_subjects = ['T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T10', 'T12', 'T13', 'T14', 'T16', 'T17', 'T18']
#params.dest_subjects = ['T19', 'T20', 'T21', 'T1']
params.source = "train"
params.dest = "test"

[[preprocessing]]
kind = "PrintHARDataModelSummary"

[[preprocessing]]
kind = "DatamodelConverter"

[[preprocessing]] # Must be applied before Class2BinMatrix and DatasetSplitter
kind = "Window"
#params.size = 32
#params.stride = 8
params.size = 64
params.stride = 16
params.unique_label_per_window = true
params.no_overlapping_labels = false

[[preprocessing]] # Must be applied after Window
kind = "Class2BinMatrix"
params.classes = 7 # PACK-2 12 classes, T1 15 classes, PACK-2+3 13 classes # 7 without STANDING

#[[preprocessing]]
#kind = "Normalize"
#params.method = 'z-score'
#params.axis = 0
#params.debug = true

#[[data_augmentation]]
#kind = "TimeShifting"

#FIXME: disable
#[[data_augmentation]]
#kind = "TimeWarping"
#params.sigma = 0.05

#[[data_augmentation]]
#kind = "Rotation"
#params.sigma = 0.05

#[[postprocessing]]
#kind = "FuseBatchNorm"
#export = true

[[postprocessing]]
kind = "DLSOMFineTuning"
params.epochs = 3
params.subject='T3'
params.test_ratio = 0.5
params.relabel = 'original'
#params.dsom.learning_rate = 0.11273174649 # original/3
#params.dsom.elasticity = 0.95811548361 # original/2
#params.dsom.learning_rate = 0.0511273174649 # original/3
#params.dsom.elasticity = 0.595811548361 # original/2
#params.dsom.learning_rate = 0.5174683297767348
#params.dsom.elasticity = 0.7136293252868753
#params.dsom.learning_rate = 0.10349366595 # 0.5174683297767348
#params.dsom.elasticity = 0.14272586505 # 0.7136293252868753
#params.dsom.learning_rate = 0.5174683297767348
#params.dsom.elasticity = 0.7136293252868753 
#params.dsom.learning_rate = 0.25873416488
#params.dsom.elasticity = 0.35681466264
#params.dsom.learning_rate = 0.10349366595 # 0.5174683297767348
#params.dsom.elasticity = 0.14272586505 # 0.7136293252868753
#params.dsom.elasticity = 5.7136293252868753 
#params.dsom.elasticity = 5.7136293252868753 
params.shuffle = true
#params.label_ratio = 0.0056
params.label_ratio = 1.0
params.drop_unlabelled = true
#params.replay.source = 'labelled'
#params.replay.duplicate = 2


[model_template]
kind = "DLSOM"

params.dl.kind = "ResNet"
#params.dl.epochs = 750
params.dl.epochs = 0 # Do not train DL model
params.dl.load = true # Load pre-trained DL model
params.dl.batch_size = 768
params.dl.params.prepool 	= 1
params.dl.params.strides	= [1, 2]
params.dl.params.num_blocks	= [2]
params.dl.params.filters 	= [32, 32]
params.dl.params.kernel_sizes 	= [7, 3, 3]
params.dl.params.paddings	= [1, 1, 1]
params.dl.params.batch_norm 	= false

params.fm_output = 'avg_pool'

#params.som.epochs = 50
params.som.epochs = 0
params.som.batch_size = 256
#params.som.params.som_layer.kind = "IsolatedClustersDSOM"
#params.som.params.som_layer.kind = "DSOM"
params.som.params.som_layer.kind = "DSOM"
#params.som.params.neurons = [8, 8]
params.som.params.neurons = [8, 8]
#params.som.params.label_sigma = 1.0450523100480082
params.som.params.label_sigma = 4.877948923266619 
#params.som.params.som_layer.params.learning_rate = 0.0034
#params.som.params.som_layer.params.elasticity = 0.078
#params.som.params.som_layer.params.learning_rate = 0.33819523946879154
params.som.params.som_layer.params.learning_rate = 0.5174683297767348 
#params.som.params.som_layer.params.elasticity = 1.9162309672240037
#params.som.params.som_layer.params.elasticity = 0.7136293252868753 
#params.som.params.som_layer.params.elasticity = 5.7136293252868753 
#params.som.params.som_layer.params.elasticity = 7.7136293252868753 
params.som.params.som_layer.params.elasticity = 1.42725865057

load = true
train = false
evaluate = false


[[model]]
name = "ellciehar_dlsom_resnet_som8x8"
disabled = false
params.dl.name = "ellciehar_resnetv1_32"


[parameter_research]
params.optimize.params.n_trials = 100
study.load = false
study.params.direction = "maximize"
study.study_name = "Ellcie-HAR_DLDSOM_ResNet_parameter_research"
study.params.storage = "sqlite:///out/parameter_research.sqlite"
study.params.load_if_exists = true

[parameter_research.trial]
params.som.params.label_sigma.kind = 'suggest_float'
params.som.params.label_sigma.params.name = 'label_sigma'
params.som.params.label_sigma.params.low = 0.25
params.som.params.label_sigma.params.high = 1.75
#params.som.epochs.kind = 'suggest_int'
#params.som.epochs.params.name = 'epochs'
#params.som.epochs.params.low = 1
#params.som.epochs.params.high = 60
